"""Auto plan chat manager agent."""

import logging
from typing import Dict, List, Optional, Tuple

import lyricore as lc

from dbgpt.core.interface.message import ModelMessageRoleType

from ..action.base import ActionOutput
from ..agent import (
    ActorProxyAgent,
    AgentMessage,
    AgentMessageRequest,
    AgentStateTaskResult,
)
from ..agent_manage import mentioned_agents, participant_roles
from ..base_team import ManagerAgent
from ..memory.gpts.base import GptsPlan
from ..plan.planner_agent import PlannerAgent
from ..profile import DynConfig, ProfileConfig
from ..schema import Status

logger = logging.getLogger(__name__)


class AutoPlanChatManager(ManagerAgent):
    """A chat manager agent that can manage a team chat of multiple agents."""

    profile: ProfileConfig = ProfileConfig(
        name=DynConfig(
            "AutoPlanChatManager",
            category="agent",
            key="dbgpt_agent_plan_team_auto_plan_profile_name",
        ),
        role=DynConfig(
            "PlanManager",
            category="agent",
            key="dbgpt_agent_plan_team_auto_plan_profile_role",
        ),
        goal=DynConfig(
            "Advance the task plan generated by the planning agent. If the plan "
            "does not pre-allocate an agent, it needs to be coordinated with the "
            "appropriate agent to complete.",
            category="agent",
            key="dbgpt_agent_plan_team_auto_plan_profile_goal",
        ),
        desc=DynConfig(
            "Advance the task plan generated by the planning agent.",
            category="agent",
            key="dbgpt_agent_plan_team_auto_plan_profile_desc",
        ),
    )

    def __init__(self, **kwargs):
        """Create a new AutoPlanChatManager instance."""
        super().__init__(**kwargs)
        self._plan_cls = PlannerAgent
        self._plan: Dict = {}
        self.current_rounds = 0
        self._worker_agent_to_plan: Dict[str, GptsPlan] = {}

    async def process_rely_message(self, conv_id: str, now_plan: GptsPlan):
        """Process the dependent message."""
        rely_prompt = None
        rely_messages: List[Dict] = []

        if now_plan.rely and len(now_plan.rely) > 0:
            rely_tasks_list = now_plan.rely.split(",")
            rely_tasks_list_int = [int(i) for i in rely_tasks_list]
            rely_tasks = await self.memory.gpts_memory.get_by_conv_id_and_num(
                conv_id, rely_tasks_list_int
            )
            if rely_tasks:
                rely_prompt = (
                    "Read the result data of the dependent steps in the above"
                    " historical message to complete the current goal:"
                )
                for rely_task in rely_tasks:
                    rely_messages.append(
                        {
                            "content": rely_task.sub_task_content,
                            "role": ModelMessageRoleType.HUMAN,
                            "name": rely_task.sub_task_agent,
                        }
                    )
                    rely_messages.append(
                        {
                            "content": rely_task.result,
                            "role": ModelMessageRoleType.AI,
                            "name": rely_task.sub_task_agent,
                        }
                    )
        return rely_prompt, rely_messages

    def select_speaker_msg(self, agents: List[ActorProxyAgent]) -> str:
        """Return the message for selecting the next speaker."""
        agent_names = [agent.name for agent in agents]
        return (
            "You are in a role play game. The following roles are available:\n"
            f"   {participant_roles(agents)}.\n"
            "   Read the following conversation.\n"
            f"   Then select the next role from {agent_names} to play.\n"
            "   The role can be selected repeatedly.Only return the role."
        )

    async def select_speaker(
        self,
        last_speaker: ActorProxyAgent,
        selector: ActorProxyAgent,
        now_goal_context: Optional[str] = None,
        pre_allocated: Optional[str] = None,
    ) -> Tuple[ActorProxyAgent, Optional[str]]:
        """Select the next speaker."""
        agents = self.agents

        if pre_allocated:
            # Preselect speakers
            logger.info(f"Preselect speakers:{pre_allocated}")
            name = pre_allocated
            model = None
        else:
            # auto speaker selection
            # TODO selector a_thinking It has been overwritten and cannot be used.
            agent_names = [agent.name for agent in agents]
            fina_name, model = await selector.thinking(
                messages=[
                    AgentMessage(
                        role=ModelMessageRoleType.HUMAN,
                        content="Read and understand the following task content and"
                        " assign the appropriate role to complete the task.\n"
                        f"Task content: {now_goal_context},\n"
                        f"Select the role from: {agent_names},\n"
                        f"Please only return the role, such as: {agents[0].name}",
                    )
                ],
                prompt=self.select_speaker_msg(agents),
            )
            if not fina_name:
                raise ValueError("Unable to select next speaker!")
            else:
                name = fina_name

        # If exactly one agent is mentioned, use it. Otherwise, leave the OAI response
        # unmodified
        mentions = mentioned_agents(name, agents)
        if len(mentions) == 1:
            name = next(iter(mentions))
        else:
            logger.warning(
                "GroupChat select_speaker failed to resolve the next speaker's name. "
                f"This is because the speaker selection OAI call returned:\n{name}"
            )

        # Return the result
        try:
            return self.agent_by_name(name), model
        except Exception as e:
            logger.exception(f"auto select speaker failed!{str(e)}")
            raise ValueError("Unable to select next speaker!")

    @lc.on(AgentStateTaskResult)
    async def handle_agent_state_message(self, state: AgentStateTaskResult, ctx):
        if not isinstance(state, AgentStateTaskResult):
            # Ignore non-task-result state messages
            return
        self.current_rounds = max(self.current_rounds, state.rounds)
        if state.role == self._plan_cls.curr_cls_role():
            if not state.is_success:
                err_msg = f"Planning agent reported failure: {state.result if state.result else ''}"
                logger.error(err_msg)
                action_report = ActionOutput(
                    is_exe_success=False,
                    content=err_msg,
                )
                await self._complete_plan(action_report)
                return
            else:
                plans = await self.memory.gpts_memory.get_by_conv_id(
                    self.not_null_agent_context.conv_id
                )
                task_num_to_plan = {plan.sub_task_num: plan for plan in plans}
                plan_dependencies: Dict[int, List[int]] = {}
                for plan in plans:
                    sub_task_num = plan.sub_task_num
                    rely_tasks_list = plan.rely.split(",")
                    rely_tasks_list_int = [
                        int(i) for i in rely_tasks_list if i.strip() != ""
                    ]
                    plan_dependencies[sub_task_num] = rely_tasks_list_int

                self._plan = {
                    "plans": task_num_to_plan,
                    "dependencies": plan_dependencies,
                    "status": {plan.sub_task_num: plan.state for plan in plans},
                }
                await self._start_ready_tasks()
                return

        # Handle task result messages from worker agents
        action_report, final_message = await self._handle_task_result(state)
        if action_report:
            await self._complete_plan(action_report)
            return

        need_adjustment = await self._check_plan_adjustment_need(state)
        if not need_adjustment:
            # No need to adjust the plan
            if state.is_success:
                to_run_tasks = await self._start_ready_tasks()
                if to_run_tasks > 0:
                    logger.info(f"Started {to_run_tasks} ready tasks.")
                else:
                    logger.info("No ready tasks to start.")
                    action_report = ActionOutput(
                        is_exe_success=True,
                        content=final_message,
                    )
                    await self._complete_plan(action_report)
            else:
                logger.error(
                    f"Task {state.name} failed: {state.result if state.result else ''}"
                )
                action_report = ActionOutput(
                    is_exe_success=False,
                    content=state.result if state.result else "",
                )
                await self._complete_plan(action_report)
        else:
            # Plan adjustment needed (not implemented)
            logger.warning("Plan adjustment needed but not implemented.")
            action_report = ActionOutput(
                is_exe_success=False,
                content="Plan adjustment needed but not implemented.",
            )
            await self._complete_plan(action_report)

    async def _handle_task_result(self, state: AgentStateTaskResult):
        task_uniq_key = self.get_worker_agent_key(state.role, state.name)
        plan = self._worker_agent_to_plan.get(task_uniq_key, None)
        final_message = None
        if not plan:
            logger.error(f"Cannot find the plan for agent {task_uniq_key}")
            return ActionOutput(
                is_exe_success=False,
                content=f"Cannot find the plan for agent {task_uniq_key}",
            ), None
        final_message = state.result
        if state.is_success:
            action_report = state.action_report
            if action_report:
                plan_result = action_report.content
                final_message = action_report.view or action_report.content
            # TODO: run update_task in a separate thread to avoid blocking
            await self.memory.gpts_memory.complete_task(
                self.not_null_agent_context.conv_id,
                plan.task_uid,
                plan_result,
            )
            plan.state = Status.COMPLETE.value
            return None, final_message
        else:
            plan_result = state.result
            # TODO: run update_task in a separate thread to avoid blocking
            await self.memory.gpts_memory.update_task(
                self.not_null_agent_context.conv_id,
                plan.sub_task_num,
                Status.FAILED.value,
                plan.retry_times + 1,
                state.name,
                "",
                plan_result,
            )
            plan.state = Status.FAILED.value
            return ActionOutput(
                is_exe_success=False, content=plan_result
            ), final_message

    async def _start_plan(self, current_goal: str, rounds: int):
        actor_ctx = lc.get_current_message_context()
        conv_uid = self.not_null_agent_context.conv_id
        i = 0

        planner_ref = await actor_ctx.spawn(
            self._plan_cls,
            f"_planner_agent_{self._plan_cls.curr_cls_name()}_{conv_uid}_{i}",
            agent_context=self.agent_context,
            llm_config=self.llm_config,
            memory=self.memory,
            # agents=self.agents,
        )
        await planner_ref.hire(self.agents)
        req = AgentMessageRequest(
            message=AgentMessage.from_llm_message(
                {"content": current_goal, "rounds": rounds}
            ),
            sender=self.self_proxy(),
            # reviewer=reviewer,
        )
        # Subscribe to the planner agent's state messages
        # monitor_ref = await actor_ctx.spawn(AgentStateMonitorActor, f"_agent_state_actor_{conv_uid}_{i}")
        await planner_ref.subscribe.tell(actor_ctx.self_ref)
        # await planner_ref.subscribe.tell(monitor_ref)
        await planner_ref.tell(req)
